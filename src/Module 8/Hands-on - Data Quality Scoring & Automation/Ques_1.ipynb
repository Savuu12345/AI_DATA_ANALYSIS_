{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Understanding and Defining Data Quality Metrics\n",
    "**Description**: Learn how to define basic data quality metrics such as completeness, validity, and uniqueness for a simple dataset.\n",
    "\n",
    "**Steps**:\n",
    "1. Dataset: Use a CSV with columns like Name , Email , Age .\n",
    "2. Metric Definitions:\n",
    "    - Completeness: Percentage of non-null values.\n",
    "    - Validity: % of email fields containing @ .\n",
    "    - Uniqueness: Count distinct entries in the Email column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completeness - Name: 0.83\n",
      "Completeness - Email: 1.00\n",
      "Completeness - Age: 0.83\n",
      "Validity - Email: 0.67\n",
      "Uniqueness - Email: 6\n"
     ]
    }
   ],
   "source": [
    "# Write your code from here\n",
    "# Write your code from here\n",
    "import pandas as pd\n",
    "\n",
    "def calculate_completeness(series):\n",
    "    return series.count() / len(series) if len(series) > 0 else 0.0\n",
    "\n",
    "def calculate_validity_email(series):\n",
    "    valid_count = series.astype(str).str.contains('@').sum()\n",
    "    return valid_count / len(series) if len(series) > 0 else 0.0\n",
    "\n",
    "def calculate_uniqueness(series):\n",
    "    return series.nunique()\n",
    "\n",
    "data = {'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve', None],\n",
    "        'Email': ['alice@example.com', 'bob@example.com', 'charlie@example.com', 'david.example', 'eve@example.com', ''],\n",
    "        'Age': [25, 30, 22, None, 28, 31]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "completeness_name = calculate_completeness(df['Name'])\n",
    "completeness_email = calculate_completeness(df['Email'])\n",
    "completeness_age = calculate_completeness(df['Age'])\n",
    "\n",
    "validity_email = calculate_validity_email(df['Email'])\n",
    "\n",
    "uniqueness_email = calculate_uniqueness(df['Email'])\n",
    "\n",
    "print(f\"Completeness - Name: {completeness_name:.2f}\")\n",
    "print(f\"Completeness - Email: {completeness_email:.2f}\")\n",
    "print(f\"Completeness - Age: {completeness_age:.2f}\")\n",
    "print(f\"Validity - Email: {validity_email:.2f}\")\n",
    "print(f\"Uniqueness - Email: {uniqueness_email}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Calculating Data Quality Score\n",
    "**Description**: Aggregate multiple metrics to calculate an overall data quality score.\n",
    "\n",
    "**Steps**:\n",
    "1. Formula: Simple average of all metrics defined in Task 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completeness - Name: 0.83\n",
      "Completeness - Email: 1.00\n",
      "Completeness - Age: 0.83\n",
      "Validity - Email: 0.67\n",
      "Uniqueness - Email: 1.00\n",
      "Overall Data Quality Score: 0.87\n"
     ]
    }
   ],
   "source": [
    "# Write your code from here\n",
    "# Write your code from here\n",
    "import pandas as pd\n",
    "\n",
    "def calculate_completeness(series):\n",
    "    return series.count() / len(series) if len(series) > 0 else 0.0\n",
    "\n",
    "def calculate_validity_email(series):\n",
    "    valid_count = series.astype(str).str.contains('@').sum()\n",
    "    return valid_count / len(series) if len(series) > 0 else 0.0\n",
    "\n",
    "def calculate_uniqueness(series):\n",
    "    return series.nunique() / len(series) if len(series) > 0 else 0.0\n",
    "\n",
    "data = {'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve', None],\n",
    "        'Email': ['alice@example.com', 'bob@example.com', 'charlie@example.com', 'david.example', 'eve@example.com', ''],\n",
    "        'Age': [25, 30, 22, None, 28, 31]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "completeness_name = calculate_completeness(df['Name'])\n",
    "completeness_email = calculate_completeness(df['Email'])\n",
    "completeness_age = calculate_completeness(df['Age'])\n",
    "\n",
    "validity_email = calculate_validity_email(df['Email'])\n",
    "\n",
    "uniqueness_email = calculate_uniqueness(df['Email'])\n",
    "\n",
    "data_quality_score = (completeness_name + completeness_email + completeness_age + validity_email + uniqueness_email) / 5\n",
    "\n",
    "print(f\"Completeness - Name: {completeness_name:.2f}\")\n",
    "print(f\"Completeness - Email: {completeness_email:.2f}\")\n",
    "print(f\"Completeness - Age: {completeness_age:.2f}\")\n",
    "print(f\"Validity - Email: {validity_email:.2f}\")\n",
    "print(f\"Uniqueness - Email: {uniqueness_email:.2f}\")\n",
    "print(f\"Overall Data Quality Score: {data_quality_score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Creating Expectations for a CSV\n",
    "**Description**: Develop basic data quality expectations using Great Expectations.\n",
    "\n",
    "**Steps**:\n",
    "1. Expectation Suite\n",
    "2. Define Expectations for Completeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "PandasDatasource.add_dataframe_asset() got an unexpected keyword argument 'dataframe'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m df\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m datasource\u001b[38;5;241m=\u001b[39mcontext\u001b[38;5;241m.\u001b[39mdata_sources\u001b[38;5;241m.\u001b[39madd_pandas(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmy_pandas_datasource\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m data_asset\u001b[38;5;241m=\u001b[39m\u001b[43mdatasource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_dataframe_asset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmy_dataframe_asset\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mdataframe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m batch_request\u001b[38;5;241m=\u001b[39mdata_asset\u001b[38;5;241m.\u001b[39mbuild_batch_request()\n\u001b[1;32m      8\u001b[0m validator\u001b[38;5;241m=\u001b[39mcontext\u001b[38;5;241m.\u001b[39mget_validator(batch_request\u001b[38;5;241m=\u001b[39mbatch_request,create_expectation_suite_with_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour_data_suite\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: PandasDatasource.add_dataframe_asset() got an unexpected keyword argument 'dataframe'"
     ]
    }
   ],
   "source": [
    "import great_expectations as gx\n",
    "import pandas as pd\n",
    "context=gx.get_context()\n",
    "df=pd.read_csv(\"data.csv\")\n",
    "datasource=context.data_sources.add_pandas(\"my_pandas_datasource\")\n",
    "data_asset=datasource.add_dataframe_asset(\"my_dataframe_asset\",dataframe=df)\n",
    "batch_request=data_asset.build_batch_request()\n",
    "validator=context.get_validator(batch_request=batch_request,create_expectation_suite_with_name=\"your_data_suite\")\n",
    "validator.expect_column_to_exist(\"your_column_name\")\n",
    "validator.expect_column_values_to_not_be_null(\"your_column_name\")\n",
    "validator.save_expectation_suite(discard_failed_expectations=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4: Running and Validating Expectations\n",
    "**Description**: Run the created expectations and generate an output report.\n",
    "\n",
    "**Steps**:\n",
    "1. Validate\n",
    "2. Generate HTML Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code from here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5: Automating Data Quality Score Calculation\n",
    "**Description**: Automate the data quality score via a script that integrates with Great\n",
    "Expectations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code from here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6: Leveraging Data Quality Metrics for Automated Data Cleaning\n",
    "**Description**: Implement a system where if data quality metrics fall below a threshold,\n",
    "automated data cleaning scripts are triggered.\n",
    "\n",
    "**Steps**:\n",
    "1. Define Cleaning Logic\n",
    "2. Integrate with Great Expectations:\n",
    "    - Use an action within the Great Expectations action list that only triggers if quality score is below a threshold, automating the cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code from here\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
