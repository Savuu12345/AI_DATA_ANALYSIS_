{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Understanding and Defining Data Quality Metrics\n",
    "**Description**: Learn how to define basic data quality metrics such as completeness, validity, and uniqueness for a simple dataset.\n",
    "\n",
    "**Steps**:\n",
    "1. Dataset: Use a CSV with columns like Name , Email , Age .\n",
    "2. Metric Definitions:\n",
    "    - Completeness: Percentage of non-null values.\n",
    "    - Validity: % of email fields containing @ .\n",
    "    - Uniqueness: Count distinct entries in the Email column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completeness - Name: 0.83\n",
      "Completeness - Email: 1.00\n",
      "Completeness - Age: 0.83\n",
      "Validity - Email: 0.67\n",
      "Uniqueness - Email: 6\n"
     ]
    }
   ],
   "source": [
    "# Write your code from here\n",
    "# Write your code from here\n",
    "import pandas as pd\n",
    "\n",
    "def calculate_completeness(series):\n",
    "    return series.count() / len(series) if len(series) > 0 else 0.0\n",
    "\n",
    "def calculate_validity_email(series):\n",
    "    valid_count = series.astype(str).str.contains('@').sum()\n",
    "    return valid_count / len(series) if len(series) > 0 else 0.0\n",
    "\n",
    "def calculate_uniqueness(series):\n",
    "    return series.nunique()\n",
    "\n",
    "data = {'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve', None],\n",
    "        'Email': ['alice@example.com', 'bob@example.com', 'charlie@example.com', 'david.example', 'eve@example.com', ''],\n",
    "        'Age': [25, 30, 22, None, 28, 31]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "completeness_name = calculate_completeness(df['Name'])\n",
    "completeness_email = calculate_completeness(df['Email'])\n",
    "completeness_age = calculate_completeness(df['Age'])\n",
    "\n",
    "validity_email = calculate_validity_email(df['Email'])\n",
    "\n",
    "uniqueness_email = calculate_uniqueness(df['Email'])\n",
    "\n",
    "print(f\"Completeness - Name: {completeness_name:.2f}\")\n",
    "print(f\"Completeness - Email: {completeness_email:.2f}\")\n",
    "print(f\"Completeness - Age: {completeness_age:.2f}\")\n",
    "print(f\"Validity - Email: {validity_email:.2f}\")\n",
    "print(f\"Uniqueness - Email: {uniqueness_email}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Calculating Data Quality Score\n",
    "**Description**: Aggregate multiple metrics to calculate an overall data quality score.\n",
    "\n",
    "**Steps**:\n",
    "1. Formula: Simple average of all metrics defined in Task 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completeness - Name: 0.83\n",
      "Completeness - Email: 1.00\n",
      "Completeness - Age: 0.83\n",
      "Validity - Email: 0.67\n",
      "Uniqueness - Email: 1.00\n",
      "Overall Data Quality Score: 0.87\n"
     ]
    }
   ],
   "source": [
    "# Write your code from here\n",
    "# Write your code from here\n",
    "import pandas as pd\n",
    "\n",
    "def calculate_completeness(series):\n",
    "    return series.count() / len(series) if len(series) > 0 else 0.0\n",
    "\n",
    "def calculate_validity_email(series):\n",
    "    valid_count = series.astype(str).str.contains('@').sum()\n",
    "    return valid_count / len(series) if len(series) > 0 else 0.0\n",
    "\n",
    "def calculate_uniqueness(series):\n",
    "    return series.nunique() / len(series) if len(series) > 0 else 0.0\n",
    "\n",
    "data = {'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve', None],\n",
    "        'Email': ['alice@example.com', 'bob@example.com', 'charlie@example.com', 'david.example', 'eve@example.com', ''],\n",
    "        'Age': [25, 30, 22, None, 28, 31]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "completeness_name = calculate_completeness(df['Name'])\n",
    "completeness_email = calculate_completeness(df['Email'])\n",
    "completeness_age = calculate_completeness(df['Age'])\n",
    "\n",
    "validity_email = calculate_validity_email(df['Email'])\n",
    "\n",
    "uniqueness_email = calculate_uniqueness(df['Email'])\n",
    "\n",
    "data_quality_score = (completeness_name + completeness_email + completeness_age + validity_email + uniqueness_email) / 5\n",
    "\n",
    "print(f\"Completeness - Name: {completeness_name:.2f}\")\n",
    "print(f\"Completeness - Email: {completeness_email:.2f}\")\n",
    "print(f\"Completeness - Age: {completeness_age:.2f}\")\n",
    "print(f\"Validity - Email: {validity_email:.2f}\")\n",
    "print(f\"Uniqueness - Email: {uniqueness_email:.2f}\")\n",
    "print(f\"Overall Data Quality Score: {data_quality_score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Creating Expectations for a CSV\n",
    "**Description**: Develop basic data quality expectations using Great Expectations.\n",
    "\n",
    "**Steps**:\n",
    "1. Expectation Suite\n",
    "2. Define Expectations for Completeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'great_expectations'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Write your code from here\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgreat_expectations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_context\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataContext\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgreat_expectations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbatch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RuntimeBatchRequest\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgreat_expectations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_connector\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RuntimeDataConnector\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'great_expectations'"
     ]
    }
   ],
   "source": [
    "# Write your code from here\n",
    "import pandas as pd\n",
    "from great_expectations.data_context import DataContext\n",
    "from great_expectations.core.batch import RuntimeBatchRequest\n",
    "from great_expectations.data_connector import RuntimeDataConnector\n",
    "from great_expectations.validator.validator import Validator\n",
    "from great_expectations.core.expectation_configuration import ExpectationConfiguration\n",
    "from great_expectations.core.expectation_suite import ExpectationSuite\n",
    "data={'id':[1,2,3,4,5],'product_name':['Laptop','Mouse','Keyboard',None,'Monitor'],'price':[1200.50,25.00,75.20,150.00,300.00],'category':['Electronics','Electronics','Electronics','Peripherals','Electronics'],'quantity_sold':[100,500,200,300,None]}\n",
    "df=pd.DataFrame(data)\n",
    "try:\n",
    "    context=DataContext()\n",
    "except Exception as e:\n",
    "    from great_expectations.data_context.types.base import DataContextConfig,DatasourceConfig,ExpectationSuiteConfig\n",
    "    from great_expectations.data_context.types.resource import DataConnectorConfig\n",
    "    context_config=DataContextConfig(datasources={\"my_in_memory_datasource\":DatasourceConfig(class_name=\"PandasDatasource\",module_name=\"great_expectations.datasource\",data_connectors={\"runtime_data_connector\":DataConnectorConfig(class_name=\"RuntimeDataConnector\",module_name=\"great_expectations.data_connector\",batch_identifiers=[\"batch_id\"],)})},store_backend_defaults={\"module_name\":\"great_expectations.data_context.store\",\"class_name\":\"InMemoryStoreBackend\"},config_variables_file_path=None,anonymous_usage_statistics={\"enabled\":False},checkpoint_store_name=\"checkpoint_store\",evaluation_parameter_store_name=\"evaluation_parameter_store\",expectations_store_name=\"expectations_store\",validation_operators=None,plugins_directory=None,concurrency_config=None,)\n",
    "    context=DataContext(project_config=context_config)\n",
    "expectation_suite_name=\"product_data_completeness_suite\"\n",
    "suite=context.create_expectation_suite(expectation_suite_name,overwrite_existing=True)\n",
    "suite.add_expectation(ExpectationConfiguration(expectation_type=\"expect_column_values_to_not_be_null\",column=\"id\"))\n",
    "suite.add_expectation(ExpectationConfiguration(expectation_type=\"expect_column_values_to_not_be_null\",column=\"product_name\"))\n",
    "suite.add_expectation(ExpectationConfiguration(expectation_type=\"expect_column_values_to_not_be_null\",column=\"price\"))\n",
    "suite.add_expectation(ExpectationConfiguration(expectation_type=\"expect_column_values_to_not_be_null\",column=\"category\"))\n",
    "suite.add_expectation(ExpectationConfiguration(expectation_type=\"expect_column_values_to_not_be_null\",column=\"quantity_sold\"))\n",
    "context.save_expectation_suite(suite,expectation_suite_name)\n",
    "batch_request=RuntimeBatchRequest(datasource_name=\"my_in_memory_datasource\",data_connector_name=\"runtime_data_connector\",data_asset_name=\"my_data_asset\",runtime_parameters={\"batch_data\":df},batch_identifiers={\"batch_id\":\"my_first_batch\"},)\n",
    "validator=context.get_validator(batch_request=batch_request,expectation_suite_name=expectation_suite_name)\n",
    "validation_result=validator.validate()\n",
    "print(validation_result.to_json_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4: Running and Validating Expectations\n",
    "**Description**: Run the created expectations and generate an output report.\n",
    "\n",
    "**Steps**:\n",
    "1. Validate\n",
    "2. Generate HTML Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code from here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5: Automating Data Quality Score Calculation\n",
    "**Description**: Automate the data quality score via a script that integrates with Great\n",
    "Expectations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code from here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6: Leveraging Data Quality Metrics for Automated Data Cleaning\n",
    "**Description**: Implement a system where if data quality metrics fall below a threshold,\n",
    "automated data cleaning scripts are triggered.\n",
    "\n",
    "**Steps**:\n",
    "1. Define Cleaning Logic\n",
    "2. Integrate with Great Expectations:\n",
    "    - Use an action within the Great Expectations action list that only triggers if quality score is below a threshold, automating the cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code from here\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
