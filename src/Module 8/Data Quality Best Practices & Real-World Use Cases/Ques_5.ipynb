{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AI/ML â€“ Improving Model Performance with Clean Data\n",
    "\n",
    "**Task 1**: Data Preprocessing for Models\n",
    "\n",
    "**Objective**: Enhance data quality for better AI/ML outcomes.\n",
    "\n",
    "**Steps**:\n",
    "1. Choose a dataset for training an AI/ML model.\n",
    "2. Identify common data issues like null values, redundant features, or noisydata.\n",
    "3. Apply preprocessing methods such as imputation, normalization, or feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#CreateSampleDatasetforAIMLwithIssues\n",
    "data={\n",
    "'feature1':[10,20,np.nan,40,50,60,70,80,90,100,10,20,30,40,np.nan],\n",
    "'feature2':['A','B','A','C','B','A','C','B','A','C','B',None,'A','C','B'],\n",
    "'feature3':[1000,2000,1500,np.nan,3000,4000,3500,5000,2500,4500,1000,2000,1500,2500,3000],\n",
    "'feature4':np.random.normal(50,15,15),\n",
    "'target':[0,1,0,1,0,1,0,1,0,1,0,1,0,1,0]\n",
    "}\n",
    "df=pd.DataFrame(data)\n",
    "\n",
    "#IdentifyNumericalandCategoricalFeatures\n",
    "numerical_features=['feature1','feature3','feature4']\n",
    "categorical_features=['feature2']\n",
    "target_column='target'\n",
    "\n",
    "#DefinePreprocessingSteps\n",
    "#NumericalPipeline:ImputationthenScaling\n",
    "numerical_transformer=Pipeline(steps=[\n",
    "('imputer',SimpleImputer(strategy='mean')),\n",
    "('scaler',StandardScaler())\n",
    "])\n",
    "\n",
    "#CategoricalPipeline:ImputationthenOneHotEncoding\n",
    "categorical_transformer=Pipeline(steps=[\n",
    "('imputer',SimpleImputer(strategy='most_frequent')),\n",
    "('onehot',OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "#CreateColumnTransformer\n",
    "preprocessor=ColumnTransformer(\n",
    "transformers=[\n",
    "('num',numerical_transformer,numerical_features),\n",
    "('cat',categorical_transformer,categorical_features)\n",
    "])\n",
    "\n",
    "#SplitData(OptionalbutgoodpracticeforML)\n",
    "X=df.drop(columns=[target_column])\n",
    "y=df[target_column]\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "\n",
    "#ApplyPreprocessingtoTrainingData\n",
    "X_train_processed=preprocessor.fit_transform(X_train)\n",
    "\n",
    "#TransformTestData\n",
    "X_test_processed=preprocessor.transform(X_test)\n",
    "\n",
    "#DemonstrateFeatureEngineering(example:creatinganewfeature)\n",
    "df['feature_engineered']=df['feature1'].fillna(df['feature1'].mean())*df['feature3'].fillna(df['feature3'].mean())\n",
    "#Youwouldtheninclude'feature_engineered'inyourfeaturlistforpreprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2**: Evaluate Model Performance\n",
    "\n",
    "**Objective**: Assess the impact of data quality improvements on model performance.\n",
    "\n",
    "**Steps**:\n",
    "1. Train a simple ML model with and without preprocessing.\n",
    "2. Analyze and compare model performance metrics to evaluate the impact of data quality strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BasicPreprocessing-Accuracy:0.3333Precision:0.5000Recall:0.5000F1-Score:0.5000\n",
      "ComprehensivePreprocessing-Accuracy:0.3333Precision:0.0000Recall:0.0000F1-Score:0.0000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n",
    "\n",
    "#RecreateSampleDataset\n",
    "data={\n",
    "'feature1':[10,20,np.nan,40,50,60,70,80,90,100,10,20,30,40,np.nan],\n",
    "'feature2':['A','B','A','C','B','A','C','B','A','C','B',None,'A','C','B'],\n",
    "'feature3':[1000,2000,1500,np.nan,3000,4000,3500,5000,2500,4500,1000,2000,1500,2500,3000],\n",
    "'feature4':np.random.normal(50,15,15),\n",
    "'target':[0,1,0,1,0,1,0,1,0,1,0,1,0,1,0]\n",
    "}\n",
    "df=pd.DataFrame(data)\n",
    "\n",
    "numerical_features=['feature1','feature3','feature4']\n",
    "categorical_features=['feature2']\n",
    "target_column='target'\n",
    "\n",
    "X=df.drop(columns=[target_column])\n",
    "y=df[target_column]\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "\n",
    "#ModelWithoutComprehensivePreprocessing(BasicHandling)\n",
    "num_transformer_basic=Pipeline(steps=[('imputer',SimpleImputer(strategy='mean'))])\n",
    "cat_transformer_basic=Pipeline(steps=[('imputer',SimpleImputer(strategy='most_frequent')),('onehot',OneHotEncoder(handle_unknown='ignore'))])\n",
    "preprocessor_basic=ColumnTransformer(\n",
    "transformers=[\n",
    "('num',num_transformer_basic,numerical_features),\n",
    "('cat',cat_transformer_basic,categorical_features)\n",
    "])\n",
    "model_basic_pipeline=Pipeline(steps=[('preprocessor',preprocessor_basic),('classifier',LogisticRegression(random_state=42,solver='liblinear'))])\n",
    "model_basic_pipeline.fit(X_train,y_train)\n",
    "y_pred_basic=model_basic_pipeline.predict(X_test)\n",
    "\n",
    "accuracy_basic=accuracy_score(y_test,y_pred_basic)\n",
    "precision_basic=precision_score(y_test,y_pred_basic,zero_division=0)\n",
    "recall_basic=recall_score(y_test,y_pred_basic,zero_division=0)\n",
    "f1_basic=f1_score(y_test,y_pred_basic,zero_division=0)\n",
    "\n",
    "#ModelWithComprehensivePreprocessing(frompreviousTask1)\n",
    "numerical_transformer_comp=Pipeline(steps=[('imputer',SimpleImputer(strategy='mean')),('scaler',StandardScaler())])\n",
    "categorical_transformer_comp=Pipeline(steps=[('imputer',SimpleImputer(strategy='most_frequent')),('onehot',OneHotEncoder(handle_unknown='ignore'))])\n",
    "preprocessor_comp=ColumnTransformer(\n",
    "transformers=[\n",
    "('num',numerical_transformer_comp,numerical_features),\n",
    "('cat',categorical_transformer_comp,categorical_features)\n",
    "])\n",
    "model_comp_pipeline=Pipeline(steps=[('preprocessor',preprocessor_comp),('classifier',LogisticRegression(random_state=42,solver='liblinear'))])\n",
    "model_comp_pipeline.fit(X_train,y_train)\n",
    "y_pred_comp=model_comp_pipeline.predict(X_test)\n",
    "\n",
    "accuracy_comp=accuracy_score(y_test,y_pred_comp)\n",
    "precision_comp=precision_score(y_test,y_pred_comp,zero_division=0)\n",
    "recall_comp=recall_score(y_test,y_pred_comp,zero_division=0)\n",
    "f1_comp=f1_score(y_test,y_pred_comp,zero_division=0)\n",
    "\n",
    "print(f\"BasicPreprocessing-Accuracy:{accuracy_basic:.4f}Precision:{precision_basic:.4f}Recall:{recall_basic:.4f}F1-Score:{f1_basic:.4f}\")\n",
    "print(f\"ComprehensivePreprocessing-Accuracy:{accuracy_comp:.4f}Precision:{precision_comp:.4f}Recall:{recall_comp:.4f}F1-Score:{f1_comp:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
