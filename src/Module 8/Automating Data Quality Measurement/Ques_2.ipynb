{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Validate Data with a Custom Expectation in Great Expectations\n",
    "**Description**: Create a custom expectation and validate data with Great Expectations.\n",
    "\n",
    "**Load a sample DataFrame**\n",
    "\n",
    "data = {\n",
    "'age': [25, 30, 35, 40, 45],\n",
    "'income': [50000, 60000, 75000, None, 100000]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'great_expectations' has no attribute 'from_pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m data\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mage\u001b[39m\u001b[38;5;124m'\u001b[39m:[\u001b[38;5;241m25\u001b[39m,\u001b[38;5;241m30\u001b[39m,\u001b[38;5;241m35\u001b[39m,\u001b[38;5;241m40\u001b[39m,\u001b[38;5;241m45\u001b[39m],\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mincome\u001b[39m\u001b[38;5;124m'\u001b[39m:[\u001b[38;5;241m50000\u001b[39m,\u001b[38;5;241m60000\u001b[39m,\u001b[38;5;241m75000\u001b[39m,\u001b[38;5;28;01mNone\u001b[39;00m,\u001b[38;5;241m100000\u001b[39m]}\n\u001b[1;32m      5\u001b[0m df\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mDataFrame(data)\n\u001b[0;32m----> 6\u001b[0m validator\u001b[38;5;241m=\u001b[39m\u001b[43mge\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pandas\u001b[49m(df)\n\u001b[1;32m      7\u001b[0m validator\u001b[38;5;241m.\u001b[39mexpect_column_values_to_not_be_null(column\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincome\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m validator\u001b[38;5;241m.\u001b[39mexpect_column_values_to_be_between(column\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mage\u001b[39m\u001b[38;5;124m\"\u001b[39m,min_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m18\u001b[39m,max_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'great_expectations' has no attribute 'from_pandas'"
     ]
    }
   ],
   "source": [
    "# Write your code from here\n",
    "import great_expectations as ge\n",
    "import pandas as pd\n",
    "data={'age':[25,30,35,40,45],'income':[50000,60000,75000,None,100000]}\n",
    "df=pd.DataFrame(data)\n",
    "validator=ge.from_pandas(df)\n",
    "validator.expect_column_values_to_not_be_null(column=\"income\")\n",
    "validator.expect_column_values_to_be_between(column=\"age\",min_value=18,max_value=100)\n",
    "results=validator.validate()\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Implement a Basic Alert System for Data Quality Drops\n",
    "**Description**: Set up a basic alert system that triggers when data quality drops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'my_custom_expectations'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 10\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Import your custom expectation.\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# This MUST be done *before* loading the context, so GX knows about it.\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmy_custom_expectations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ExpectColumnValuesToBeDivisibleBy\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# --- Configuration ---\u001b[39;00m\n\u001b[1;32m     13\u001b[0m csv_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata.csv\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;66;03m# Ensure this file exists\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'my_custom_expectations'"
     ]
    }
   ],
   "source": [
    "# Write your code from here\n",
    "import pandas as pd\n",
    "from great_expectations.data_context import FileDataContext\n",
    "from great_expectations.core.batch import RuntimeBatchRequest\n",
    "from great_expectations.core.yaml_handler import YAMLHandler\n",
    "import os\n",
    "\n",
    "# Import your custom expectation.\n",
    "# This MUST be done *before* loading the context, so GX knows about it.\n",
    "from my_custom_expectations import ExpectColumnValuesToBeDivisibleBy\n",
    "\n",
    "# --- Configuration ---\n",
    "csv_file_path = 'data.csv' # Ensure this file exists\n",
    "expectation_suite_name = \"my_sample_dataframe_suite\"\n",
    "checkpoint_name = \"my_daily_data_quality_check\"\n",
    "\n",
    "# --- Sample DataFrame (same as before) ---\n",
    "data = {\n",
    "    'age': [25, 30, 35, 40, 45, 27, None],\n",
    "    'income': [50000, 60000, 75000, None, 100000, 55000, 80000]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# --- Great Expectations Workflow ---\n",
    "\n",
    "# 1. Load the Data Context\n",
    "context = FileDataContext(project_root_dir='.')\n",
    "\n",
    "# Manually add custom expectation for this session if not configured in great_expectations.yml\n",
    "context.add_custom_expectation(ExpectColumnValuesToBeDivisibleBy, \"column_values.divisible_by\")\n",
    "\n",
    "# 2. Create a Batch Request using your DataFrame\n",
    "batch_request = RuntimeBatchRequest(\n",
    "    datasource_name=\"my_pandas_datasource\",\n",
    "    data_connector_name=\"default_runtime_data_connector\",\n",
    "    data_asset_name=\"my_data_asset\",\n",
    "    batch_spec_passthrough={\"batch_data\": df},\n",
    ")\n",
    "\n",
    "# 3. Get a Validator and define Expectations\n",
    "print(f\"Loading/Creating expectation suite: {expectation_suite_name}\")\n",
    "validator = context.get_validator(\n",
    "    batch_request=batch_request,\n",
    "    expectation_suite_name=expectation_suite_name,\n",
    "    create_expectation_suite_if_absent=True\n",
    ")\n",
    "\n",
    "# Clear existing expectations to redefine for this run if needed, or comment out\n",
    "# validator.get_expectation_suite().clear()\n",
    "\n",
    "print(\"\\nDefining expectations...\")\n",
    "# Example 1: Custom expectation - likely to pass for most values\n",
    "validator.expect_column_values_to_be_divisible_by(column=\"age\", divisor=5, meta={\"notes\": \"Expected to have some non-divisible values due to '27' and 'None'\"})\n",
    "\n",
    "# Example 2: Custom expectation - likely to fail significantly\n",
    "validator.expect_column_values_to_be_divisible_by(column=\"age\", divisor=10, meta={\"notes\": \"Expected to fail for non-multiples of 10 and nulls\"})\n",
    "\n",
    "# Example 3: Standard GE expectation - will fail due to None\n",
    "validator.expect_column_values_to_not_be_null(column=\"age\", meta={\"notes\": \"Expected to fail due to null value in age\"})\n",
    "\n",
    "# Example 4: Another standard GE expectation - will fail due to None\n",
    "validator.expect_column_values_to_not_be_null(column=\"income\", meta={\"notes\": \"Expected to fail due to null value in income\"})\n",
    "\n",
    "# 5. Save the Expectation Suite\n",
    "print(\"\\nSaving expectation suite...\")\n",
    "validator.save_expectation_suite(discard_failed_expectations=False)\n",
    "\n",
    "# 6. Run the Validation using a Checkpoint\n",
    "# If you haven't defined this checkpoint in great_expectations/checkpoints/your_checkpoint_name.yml,\n",
    "# it will use an ephemeral one based on the parameters passed.\n",
    "# For a more persistent setup, you'd define the checkpoint in YAML.\n",
    "print(f\"\\nRunning checkpoint: {checkpoint_name}\")\n",
    "checkpoint_result = context.run_checkpoint(\n",
    "    checkpoint_name=checkpoint_name,\n",
    "    batch_request=batch_request,\n",
    "    expectation_suite_name=expectation_suite_name,\n",
    "    # This configuration defines what actions to take after validation,\n",
    "    # including building Data Docs and optionally sending notifications.\n",
    "    # For a real alert system, you'd configure actions here.\n",
    "    action_list=[\n",
    "        {\n",
    "            \"name\": \"store_validation_result\",\n",
    "            \"action\": {\"class_name\": \"StoreValidationResultAction\"},\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"store_evaluation_parameter_metrics\",\n",
    "            \"action\": {\"class_name\": \"StoreEvaluationParameterMetricsAction\"},\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"update_data_docs\",\n",
    "            \"action\": {\"class_name\": \"UpdateDataDocsAction\"},\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "# --- Step 7: Implement Basic Alert System ---\n",
    "print(\"\\n--- Basic Alert System Check ---\")\n",
    "\n",
    "if not checkpoint_result.success:\n",
    "    print(\"ðŸš¨ ALERT! Data Quality Drop Detected! ðŸš¨\")\n",
    "    print(f\"Checkpoint '{checkpoint_name}' FAILED for suite '{expectation_suite_name}'.\")\n",
    "    print(\"Review the Data Docs for details on failed expectations.\")\n",
    "\n",
    "    # You could add more sophisticated alerting here:\n",
    "    # 1. Send an email:\n",
    "    #    import smtplib\n",
    "    #    from email.mime.text import MIMEText\n",
    "    #    msg = MIMEText(f\"Data quality check failed for {expectation_suite_name}. See Data Docs for more info.\")\n",
    "    #    msg['Subject'] = 'Data Quality Alert!'\n",
    "    #    msg['From'] = 'your_email@example.com'\n",
    "    #    msg['To'] = 'alert_recipient@example.com'\n",
    "    #    with smtplib.SMTP('smtp.example.com', 587) as s:\n",
    "    #        s.starttls()\n",
    "    #        s.login('your_email@example.com', 'your_password')\n",
    "    #        s.send_message(msg)\n",
    "    #    print(\"Email alert sent!\")\n",
    "\n",
    "    # 2. Post to Slack/Teams (requires webhooks or SDK)\n",
    "    #    import requests\n",
    "    #    slack_webhook_url = \"YOUR_SLACK_WEBHOOK_URL\"\n",
    "    #    payload = {\"text\": f\"ðŸš¨ Data Quality Alert! Checkpoint '{checkpoint_name}' failed for suite '{expectation_suite_name}'.\"}\n",
    "    #    response = requests.post(slack_webhook_url, json=payload)\n",
    "    #    if response.status_code == 200:\n",
    "    #        print(\"Slack alert sent!\")\n",
    "    #    else:\n",
    "    #        print(f\"Failed to send Slack alert: {response.status_code} - {response.text}\")\n",
    "\n",
    "    # 3. Log to a monitoring system\n",
    "    # import logging\n",
    "    # logging.basicConfig(level=logging.INFO)\n",
    "    # logging.info(f\"DATA_QUALITY_ALERT: Checkpoint {checkpoint_name} failed. Suite: {expectation_suite_name}\")\n",
    "\n",
    "else:\n",
    "    print(\"âœ… Data Quality is good! All expectations passed. âœ…\")\n",
    "\n",
    "# 8. Build and Open Data Docs (Optional, but highly recommended for viewing results)\n",
    "print(\"\\nBuilding Data Docs. Check your browser for the validation report.\")\n",
    "context.build_data_docs()\n",
    "context.open_data_docs()\n",
    "\n",
    "print(\"\\nValidation and Alerting process complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Real-time Data Quality Monitoring with Python and Great Expectations\n",
    "**Description**: Implement a system that monitors data quality in real-time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code from here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
