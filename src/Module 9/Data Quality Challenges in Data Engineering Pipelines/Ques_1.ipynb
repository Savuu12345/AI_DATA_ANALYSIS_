{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Detecting Missing Values during Data Ingestion\n",
    "**Description**: You have a CSV file with missing values in some columns. Write a Python script to detect and report missing values during the ingestion process.\n",
    "\n",
    "**Steps**:\n",
    "1. Load data\n",
    "2. Check for missing values\n",
    "3. Report missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import io\n",
    "def detect_missing_values(csv_data):\n",
    "    \"\"\"\n",
    "    Detects and reports missing values in a CSV file.\n",
    "    Args:\n",
    "        csv_data (str): The CSV data as a string.\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing the missing value counts for each column.\n",
    "                          Returns None if the input data is empty or an error occurs.\n",
    "    \"\"\"\n",
    "    if not csv_data:\n",
    "        print(\"Error: Empty input data.\")\n",
    "        return None\n",
    "    try:\n",
    "        # Load the CSV data into a pandas DataFrame\n",
    "        df = pd.read_csv(io.StringIO(csv_data))\n",
    "\n",
    "        missing_values = df.isnull().sum()\n",
    "        missing_values_df = pd.DataFrame(missing_values, columns=['Missing Count'])\n",
    "        missing_values_df = missing_values_df[missing_values_df['Missing Count'] > 0] # only show columns with missing values\n",
    "        if missing_values_df.empty:\n",
    "            print(\"No missing values detected.\")\n",
    "            return None  # Return None to indicate no missing values\n",
    "        return missing_values_df\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing CSV data: {e}\")\n",
    "        return None\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to execute the missing value detection.\n",
    "    \"\"\"\n",
    "    csv_data = \"\"\"\n",
    "Name,Age,City,Salary\n",
    "John,25,New York,50000\n",
    "Jane,30,London,\n",
    "Bob,,Paris,60000\n",
    "Alice,28,,55000\n",
    "\"\"\"\n",
    "    missing_values_report = detect_missing_values(csv_data)\n",
    "    if missing_values_report is not None:\n",
    "        print(\"Missing Values Report:\")\n",
    "        print(missing_values_report)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Validate Data Types during Extraction\n",
    "**Description**: You have a JSON file that should have specific data types for each field. Write a script to validate if the data types match the expected schema.\n",
    "\n",
    "**Steps**:\n",
    "1. Define expected schema\n",
    "2. Validate data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "def validate_data_types(json_data, schema):\n",
    "    \"\"\"\n",
    "    Validates the data types of a JSON object against a provided schema.\n",
    "    Args:\n",
    "        json_data (str): The JSON data as a string.\n",
    "        schema (dict): A dictionary representing the expected schema.\n",
    "            Keys are field names and values are the expected data types (e.g., 'str', 'int', 'float', 'bool').\n",
    "    Returns:\n",
    "        dict: A dictionary containing the validation results.  Each key is a field name.\n",
    "            Values are \"valid\" or \"invalid\".  Returns an empty dict on error.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        data = json.loads(json_data)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error: Invalid JSON: {e}\")\n",
    "        return {}\n",
    "    results = {}\n",
    "    for field, expected_type_str in schema.items():\n",
    "        if field not in data:\n",
    "            results[field] = \"invalid\"  # Field is missing\n",
    "            continue\n",
    "        value = data[field]\n",
    "        expected_type = None\n",
    "        if expected_type_str == 'str':\n",
    "            expected_type = str\n",
    "        elif expected_type_str == 'int':\n",
    "            expected_type = int\n",
    "        elif expected_type_str == 'float':\n",
    "            expected_type = float\n",
    "        elif expected_type_str == 'bool':\n",
    "            expected_type = bool\n",
    "        elif expected_type_str == 'list':\n",
    "            expected_type = list\n",
    "        elif expected_type_str == 'dict':\n",
    "            expected_type = dict\n",
    "        else:\n",
    "            print(f\"Warning: Unknown type '{expected_type_str}' in schema.  Skipping validation for field '{field}'.\")\n",
    "            results[field] = \"invalid\" #handles the error\n",
    "            continue\n",
    "        if not isinstance(value, expected_type):\n",
    "            results[field] = \"invalid\"\n",
    "        else:\n",
    "            results[field] = \"valid\"\n",
    "    return results\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to execute the data type validation.\n",
    "    \"\"\"\n",
    "    json_data = \"\"\"\n",
    "    {\n",
    "        \"name\": \"John Doe\",\n",
    "        \"age\": 30,\n",
    "        \"salary\": 75000.50,\n",
    "        \"is_active\": true,\n",
    "        \"hobbies\": [\"reading\", \"traveling\"],\n",
    "        \"address\": {\n",
    "            \"street\": \"123 Main St\",\n",
    "            \"city\": \"Anytown\"\n",
    "        }\n",
    "    }\n",
    "    \"\"\"\n",
    "    schema = {\n",
    "        \"name\": \"str\",\n",
    "        \"age\": \"int\",\n",
    "        \"salary\": \"float\",\n",
    "        \"is_active\": \"bool\",\n",
    "        \"hobbies\": \"list\",\n",
    "        \"address\": \"dict\"\n",
    "    }\n",
    "    results = validate_data_types(json_data, schema)\n",
    "\n",
    "    print(\"Data Type Validation Results:\")\n",
    "    for field, result in results.items():\n",
    "        print(f\"{field}: {result}\")\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Remove Duplicate Records in Data\n",
    "**Description**: You have a dataset with duplicate entries. Write a Python script to find and remove duplicate records using Pandas.\n",
    "\n",
    "**Steps**:\n",
    "1. Find duplicate records\n",
    "2. Remove duplicates\n",
    "3. Report results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import io\n",
    "def remove_duplicate_records(csv_data):\n",
    "    \"\"\"\n",
    "    Finds and removes duplicate records from CSV data using Pandas.\n",
    "    Args:\n",
    "        csv_data (str): The CSV data as a string.\n",
    "    Returns:\n",
    "        tuple: A tuple containing two DataFrames:\n",
    "            - duplicate_df: DataFrame containing the duplicate records.\n",
    "            - unique_df: DataFrame containing the unique records after removing duplicates.\n",
    "              Returns (None, None) if the input data is empty or an error occurs.\n",
    "    \"\"\"\n",
    "    if not csv_data:\n",
    "        print(\"Error: Empty input data.\")\n",
    "        return None, None\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(io.StringIO(csv_data))\n",
    "        duplicate_df = df[df.duplicated()]\n",
    "        unique_df = df.drop_duplicates()\n",
    "        if duplicate_df.empty:\n",
    "            print(\"No duplicate records found.\")\n",
    "        else:\n",
    "            print(\"Duplicate records found:\")\n",
    "        return duplicate_df, unique_df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing CSV data: {e}\")\n",
    "        return None, None\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to execute the duplicate removal process.\n",
    "    \"\"\"\n",
    "    csv_data = \"\"\"\n",
    "Name,Age,City,Salary\n",
    "John,25,New York,50000\n",
    "Jane,30,London,60000\n",
    "John,25,New York,50000\n",
    "Bob,35,Paris,70000\n",
    "Jane,30,London,60000\n",
    "Alice,28,Berlin,55000\n",
    "\"\"\"\n",
    "    duplicate_df, unique_df = remove_duplicate_records(csv_data)\n",
    "    if duplicate_df is not None and not duplicate_df.empty:\n",
    "        print(\"Duplicate Records:\")\n",
    "        print(duplicate_df)\n",
    "    if unique_df is not None:\n",
    "        print(\"\\nUnique Records:\")\n",
    "        print(unique_df)\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
