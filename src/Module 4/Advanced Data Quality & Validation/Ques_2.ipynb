{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#corrected\n",
    "# Part 1: Detecting Data Drift in AI/ML Models\n",
    "# Objective: Understand data drift, how it affects machine learning models, and techniques tomonitor it.\n",
    "# Task 1: Understanding Data Drift: Study a historical dataset used in training a simple linear regression model and\n",
    "# compare it with recent unseen data to detect drift.\n",
    "# Task 2: Monitoring Distribution Changes: Write the code to identify features that exhibit statistical distribution differences.\n",
    "# Task 3: Visualizing Data Drift: Use visualization techniques to illustrate data drift.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(42)\n",
    "X_train = np.random.rand(100, 1) * 10\n",
    "y_train = 2.5 * X_train.squeeze() + np.random.randn(100) * 2\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "X_test_drifted = np.random.rand(100, 1) * 15  \n",
    "y_test_drifted = 2.5 * X_test_drifted.squeeze() + np.random.randn(100) * 2\n",
    "y_pred_drifted = model.predict(X_test_drifted)\n",
    "mse_drifted = mean_squared_error(y_test_drifted, y_pred_drifted)\n",
    "print(f\"Mean Squared Error on Drifted Data: {mse_drifted:.2f}\")\n",
    "from scipy.stats import ks_2samp\n",
    "ks_stat, ks_p_value = ks_2samp(X_train.squeeze(), X_test_drifted.squeeze())\n",
    "print(f\"KS Statistic: {ks_stat:.4f}, P-Value: {ks_p_value:.4f}\")\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(X_train.squeeze(), color='blue', label='Training Data', kde=True, stat='density')\n",
    "sns.histplot(X_test_drifted.squeeze(), color='red', label='Drifted Test Data', kde=True, stat='density')\n",
    "plt.title('Feature Distribution Comparison')\n",
    "plt.xlabel('Feature Value')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2: Automating Data Quality Checks\n",
    "# Objective: Use Python and data quality frameworks to automate validation.\n",
    "\n",
    "# Task 1: Setting Up Automated Validation with Python\n",
    "# Task 2: Introduction to Great Expectations: Install the great_expectations package and set up a basic project.\n",
    "# Task 3: Creating Expectations with Great Expectations: Use Great Expectations to define data validation expectations for a dataset.\n",
    "# Task 1: Setting Up Automated Validation with Python\n",
    "# (This task is conceptual and depends on the specific validation needs and data sources)\n",
    "# Example using basic Python for a simple check:\n",
    "def validate_column_presence(df, column_name):\n",
    "    if column_name not in df.columns:\n",
    "        raise ValueError(f\"Column '{column_name}' is missing.\")\n",
    "    return True\n",
    "def validate_data_types(df, column_types):\n",
    "    for col, expected_type in column_types.items():\n",
    "        actual_type = df[col].dtype\n",
    "        if actual_type != expected_type:\n",
    "            raise TypeError(f\"Column '{col}' has type '{actual_type}', expected '{expected_type}'.\")\n",
    "    return True\n",
    "def run_data_validation(df):\n",
    "    try:\n",
    "        validate_column_presence(df, 'user_id')\n",
    "        validate_column_presence(df, 'age')\n",
    "        validate_data_types(df, {'user_id': 'int64', 'age': 'int64'})\n",
    "        print(\"Basic data validation checks passed.\")\n",
    "        return True\n",
    "    except (ValueError, TypeError) as e:\n",
    "        print(f\"Data validation failed: {e}\")\n",
    "        return False\n",
    "import pandas as pd\n",
    "data={'user_id':[1,2,3],'age':[25,30,'error']}\n",
    "df=pd.DataFrame(data)\n",
    "run_data_validation(df)\n",
    "\n",
    "# Task 2: Introduction to Great Expectations: Install the great_expectations package and set up a basic project.\n",
    "# (Installation is done in the terminal: pip install great_expectations)\n",
    "# (Basic project setup is typically done via the command line: great_expectations init)\n",
    "# (Assuming Great Expectations is installed and a project is initialized)\n",
    "import great_expectations as gx\n",
    "context=gx.get_context()\n",
    "print(f\"Great Expectations Data Context root directory: {context.root_directory}\")\n",
    "# Task 3: Creating Expectations with Great Expectations: Use Great Expectations to define data validation expectations for a dataset.\n",
    "expectation_suite_name=\"my_sample_expectation_suite\"\n",
    "try:\n",
    "    suite=context.get_expectation_suite(expectation_suite_name)\n",
    "    print(f\"Loaded existing Expectation Suite: {expectation_suite_name}\")\n",
    "except gx.exceptions.ExpectationSuiteNotFoundError:\n",
    "    suite=context.create_expectation_suite(\n",
    "        expectation_suite_name=expectation_suite_name,\n",
    "        overwrite_existing=True\n",
    "    )\n",
    "    print(f\"Created new Expectation Suite: {expectation_suite_name}\")\n",
    "\n",
    "data_gx={'user_id':[1,2,3,4,5],'age':[25,30,18,40,28],'signup_date':['2023-01-15','2023-02-20','2023-01-10','2023-03-01','2023-02-25']}\n",
    "df_gx=pd.DataFrame(data_gx)\n",
    "\n",
    "datasource_name=\"my_pandas_datasource\"\n",
    "datasource=context.add_pandas(name=datasource_name,dataframe=df_gx)\n",
    "data_asset_name=\"sample_data\"\n",
    "data_asset=datasource.get_asset(data_asset_name)\n",
    "batch_request=data_asset.build_batch_request()\n",
    "\n",
    "suite.add_expectation(\n",
    "    gx.expectations.expect_column_values_to_not_be_null(column=\"user_id\")\n",
    ")\n",
    "suite.add_expectation(\n",
    "    gx.expectations.expect_column_values_to_be_between(\n",
    "        column=\"age\",min_value=18,max_value=60\n",
    "    )\n",
    ")\n",
    "suite.add_expectation(\n",
    "    gx.expectations.expect_column_values_to_be_of_type(\n",
    "        column=\"signup_date\",type=\"datetime64[ns]\"\n",
    "    )\n",
    ")\n",
    "\n",
    "context.save_expectation_suite(suite)\n",
    "\n",
    "validator=context.get_validator(\n",
    "    batch_request=batch_request,\n",
    "    expectation_suite_name=expectation_suite_name\n",
    ")\n",
    "\n",
    "validation_result=validator.validate()\n",
    "print(\"\\n---Great Expectations Validation Results---\")\n",
    "if validation_result[\"success\"]:\n",
    "    print(\"Data validation successful!All expectations met.\")\n",
    "else:\n",
    "    print(\"Data validation failed.Unmet expectations:\")\n",
    "    for result in validation_result[\"results\"]:\n",
    "        if not result[\"success\"]:\n",
    "            print(f\"-Column:{result['expectation_config']['kwargs'].get('column','N/A')},Expectation:{result['expectation_config']['expectation_type']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
